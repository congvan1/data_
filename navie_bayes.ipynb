{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \t\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "\treturn round(float(sum(y_pred == y_true))/float(len(y_true)) * 100 ,2)\n",
    "\n",
    "\n",
    "class  NaiveBayes:\n",
    "\tdef __init__(self):\n",
    "\t\tself.features = list\n",
    "\t\tself.likelihoods = {}\n",
    "\t\tself.class_priors = {}\n",
    "\t\tself.pred_priors = {}\n",
    "\n",
    "\t\tself.X_train = np.array\n",
    "\t\tself.y_train = np.array\n",
    "\t\tself.train_size = int\n",
    "\t\tself.num_feats = int\n",
    "\n",
    "\tdef fit(self, X, y):\n",
    "\t\tself.features = list(X.columns)\n",
    "\t\tself.X_train = X\n",
    "\t\tself.y_train = y\n",
    "\t\tself.train_size = X.shape[0]\n",
    "\t\tself.num_feats = X.shape[1]\n",
    "\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tself.likelihoods[feature] = {}\n",
    "\t\t\tself.pred_priors[feature] = {}\n",
    "\n",
    "\t\t\tfor feat_val in np.unique(self.X_train[feature]):\n",
    "\t\t\t\tself.pred_priors[feature].update({feat_val: 0})\n",
    "\n",
    "\t\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\t\tself.likelihoods[feature].update({feat_val+'_'+outcome:0})\n",
    "\t\t\t\t\tself.class_priors.update({outcome: 0})\n",
    "\n",
    "\t\tself._calc_class_prior()\n",
    "\t\tself._calc_likelihoods()\n",
    "\t\tself._calc_predictor_prior()\n",
    "    \n",
    "    # P(c) - Prior Class Probability\n",
    "\tdef _calc_class_prior(self):\n",
    "\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\toutcome_count = sum(self.y_train == outcome)\n",
    "\t\t\tself.class_priors[outcome] = outcome_count / self.train_size\n",
    "\n",
    "    # P(x|c) - Likelihood\n",
    "\tdef _calc_likelihoods(self):\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\toutcome_count = sum(self.y_train == outcome)\n",
    "\t\t\t\tfeat_likelihood = self.X_train[feature][self.y_train[self.y_train == outcome].index.values.tolist()].value_counts().to_dict()\n",
    "\t\t\t\tfor feat_val, count in feat_likelihood.items():\n",
    "\t\t\t\t\tself.likelihoods[feature][feat_val + '_' + outcome] = count/outcome_count\n",
    "\n",
    "    # P(x)\n",
    "\tdef _calc_predictor_prior(self):\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tfeat_vals = self.X_train[feature].value_counts().to_dict()\n",
    "\t\t\tfor feat_val, count in feat_vals.items():\n",
    "\t\t\t\tself.pred_priors[feature][feat_val] = count/self.train_size\n",
    "\n",
    "    # P(c|x)\n",
    "\tdef predict(self, X):\n",
    "\t\tresults = []\n",
    "\t\tX = np.array(X)\n",
    "\t\tfor query in X:\n",
    "\t\t\tprobs_outcome = {}\n",
    "\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\tprior = self.class_priors[outcome]\n",
    "\t\t\t\tlikelihood = 1\n",
    "\t\t\t\tevidence = 1\n",
    "\t\t\t\tfor feat, feat_val in zip(self.features, query):\n",
    "\t\t\t\t\tlikelihood *= self.likelihoods[feat][feat_val + '_' + outcome]\n",
    "\t\t\t\t\tevidence *= self.pred_priors[feat][feat_val]\n",
    "\t\t\t\tposterior = (likelihood * prior) / (evidence)\n",
    "\t\t\t\tprobs_outcome[outcome] = posterior\n",
    "\t\t\tresult = max(probs_outcome, key = lambda x: probs_outcome[x])\n",
    "\t\t\tresults.append(result)\n",
    "\t\treturn np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>t</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>f</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>f</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>f</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outlook  Temp Humidity Windy Play\n",
       "0     Rainy   Hot     High     f   no\n",
       "1     Rainy   Hot     High     t   no\n",
       "2  Overcast   Hot     High     f  yes\n",
       "3     Sunny  Mild     High     f  yes\n",
       "4     Sunny  Cool   Normal     f  yes"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table(\"weather.txt\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Outlook', 'Temp', 'Humidity', 'Windy'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Split fearures and target\n",
    "X = df.drop([df.columns[-1]], axis = 1)\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "P_c = {}\n",
    "P_xc = {}\n",
    "P_x = {}\n",
    "P_cx = {}\n",
    "\n",
    "for outcome in np.unique(y):\n",
    "    outcome_count = sum(y == outcome)\n",
    "    P_c[outcome] = outcome_count / X.shape[0]\n",
    "    \n",
    "for feature in list(X.columns):\n",
    "    for outcome in np.unique(y):\n",
    "        outcome_count = sum(y == outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yes': 9, 'no': 5}\n"
     ]
    }
   ],
   "source": [
    "a = y.value_counts()\n",
    "print(dict(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_clf = NaiveBayes()\n",
    "nb_clf.fit(X, y)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(accuracy_score(y, nb_clf.predict(X))))\n",
    "\n",
    "#Query 1:\n",
    "query = np.array([['Rainy','Mild', 'Normal', 't']])\n",
    "print(\"Query 1:- {} ---> {}\".format(query, nb_clf.predict(query)))\n",
    "\n",
    "#Query 2:\n",
    "query = np.array([['Overcast','Cool', 'Normal', 't']])\n",
    "print(\"Query 2:- {} ---> {}\".format(query, nb_clf.predict(query)))\n",
    "\n",
    "#Query 3:\n",
    "query = np.array([['Sunny','Hot', 'High', 't']])\n",
    "print(\"Query 3:- {} ---> {}\".format(query, nb_clf.predict(query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           age  income student credit_rate default\n",
      "0        youth    high      no        fair      no\n",
      "1        youth    high      no   excellent      no\n",
      "2   middle_age    high      no        fair     yes\n",
      "3       senior  medium      no        fair     yes\n",
      "4       senior     low     yes        fair     yes\n",
      "5       senior     low     yes   excellent      no\n",
      "6   middle_age     low     yes   excellent     yes\n",
      "7        youth  medium      no        fair      no\n",
      "8        youth     low     yes        fair     yes\n",
      "9       senior  medium     yes        fair     yes\n",
      "10       youth  medium     yes   excellent     yes\n",
      "11  middle_age  medium      no   excellent     yes\n",
      "12  middle_age    high     yes        fair     yes\n",
      "13      senior  medium      no   excellent      no\n"
     ]
    }
   ],
   "source": [
    "# Defining a simple dataset\n",
    "attribute_names =  ['age', 'income','student', 'credit_rate']\n",
    "class_name = 'default'\n",
    "data1 ={\n",
    "    'age' : ['youth', 'youth', 'middle_age', 'senior', 'senior', 'senior','middle_age', 'youth', 'youth', 'senior', 'youth', 'middle_age','middle_age', 'senior'],\n",
    "    'income' : ['high', 'high', 'high', 'medium', 'low', 'low', 'low', 'medium','low', 'medium', 'medium', 'medium', 'high', 'medium'],\n",
    "    'student' : ['no','no','no','no','yes','yes','yes','no','yes','yes','yes','no','yes','no'],\n",
    "    'credit_rate' : ['fair', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'fair', 'fair','excellent', 'excellent', 'fair', 'excellent'],\n",
    "    'default' : ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes','yes', 'yes', 'yes', 'no']\n",
    "}\n",
    "df1 = pd.DataFrame (data1, columns=data1.keys())\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in each class is:\n",
      "yes    9\n",
      "no     5\n",
      "Name: default, dtype: int64\n",
      "\n",
      "Gini Impurity of the class is 0.459\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Calculate gini(D)\n",
    "def gini_impurity (value_counts):\n",
    "    n = value_counts.sum()\n",
    "    p_sum = 0\n",
    "    for key in value_counts.keys():\n",
    "        p_sum = p_sum  +  (value_counts[key] / n ) * (value_counts[key] / n ) \n",
    "    gini = 1 - p_sum\n",
    "    return gini\n",
    "\n",
    "class_value_counts = df1[class_name].value_counts()\n",
    "print(f'Number of samples in each class is:\\n{class_value_counts}')\n",
    "\n",
    "gini_class = gini_impurity(class_value_counts)\n",
    "print(f'\\nGini Impurity of the class is {gini_class:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youth         5\n",
      "senior        5\n",
      "middle_age    4\n",
      "Name: age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "attribute_name = 'age'\n",
    "attribute_values = df1[attribute_name].value_counts()\n",
    "print(attribute_values)\n",
    "gini_A = 0 \n",
    "for key in attribute_values.keys():\n",
    "    df_k = df1[class_name][df1[attribute_name] == key].value_counts()\n",
    "    n_k = attribute_values[key]\n",
    "    n = df1.shape[0]\n",
    "    gini_A = gini_A + (( n_k / n) * gini_impurity(df_k))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[class_name][df1[attribute_name] == 'youth'].value_counts()\n",
    "attribute_values['youth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: \n",
    "# Calculating  gini impurity for the attiributes\n",
    "def gini_split_a(attribute_name):\n",
    "    attribute_values = df1[attribute_name].value_counts()\n",
    "    gini_A = 0 \n",
    "    for key in attribute_values.keys():\n",
    "        df_k = df1[class_name][df1[attribute_name] == key].value_counts()\n",
    "        n_k = attribute_values[key]\n",
    "        n = df1.shape[0]\n",
    "        gini_A = gini_A + (( n_k / n) * gini_impurity(df_k))\n",
    "    return gini_A\n",
    "\n",
    "gini_attiribute ={}\n",
    "for key in attribute_names:\n",
    "    gini_attiribute[key] = gini_split_a(key)\n",
    "    print(f'Gini for {key} is {gini_attiribute[key]:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82258a55d1500764d1b3d80f19af3c76a05d58cf47ccab85c75254e5aad3c4be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
